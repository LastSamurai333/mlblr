{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### FORWARD PROPAGATION, BACK PROPAGATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivatives_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Read input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "Y = np.array([[1],[1],[0]])\n",
    "print (X)\n",
    "print (Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Initialize weights and biases with random values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51 0.77 0.87]\n",
      " [0.01 0.31 0.96]\n",
      " [0.51 0.32 0.54]\n",
      " [0.22 0.81 0.34]]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(14)\n",
    "wh=np.random.rand(4,3)\n",
    "wh=np.round(wh,decimals=2)\n",
    "bh=np.random.rand(1,3)\n",
    "bh=np.round(bh,decimals=2)\n",
    "wout=np.random.rand(3,1)\n",
    "wout=np.round(wout,decimals=2)\n",
    "bout=np.random.rand(1,1)\n",
    "bout=np.round(bout,decimals=2)\n",
    "print (wh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.54 0.01 0.67]]\n"
     ]
    }
   ],
   "source": [
    "print (bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21]\n",
      " [0.93]\n",
      " [0.37]]\n"
     ]
    }
   ],
   "source": [
    "print (wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75]]\n"
     ]
    }
   ],
   "source": [
    "print (bout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate hidden layer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.56 1.1  2.08]\n",
      " [1.78 1.91 2.42]\n",
      " [0.77 1.13 1.97]]\n"
     ]
    }
   ],
   "source": [
    "hidden_layer_input=np.dot(X,wh) + bh\n",
    "print (hidden_layer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Perform non-linear transformation on hidden linear input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82635335 0.75026011 0.88894403]\n",
      " [0.85569687 0.87101915 0.91833974]\n",
      " [0.68352089 0.7558389  0.87761111]]\n"
     ]
    }
   ],
   "source": [
    "hiddenlayer_activations = sigmoid(hidden_layer_input)\n",
    "print (hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Perform linear and non-linear transformation of hidden layer activation at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82635335 0.75026011 0.88894403]\n",
      " [0.85569687 0.87101915 0.91833974]\n",
      " [0.68352089 0.7558389  0.87761111]]\n"
     ]
    }
   ],
   "source": [
    "output_layer_input = np.dot(hiddenlayer_activations,wout) + bout\n",
    "print (hiddenlayer_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87546686]\n",
      " [0.88889761]\n",
      " [0.87227059]]\n"
     ]
    }
   ],
   "source": [
    "output = sigmoid(output_layer_input)\n",
    "print (output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Calculate gradient of Error(E) at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12453314]\n",
      " [ 0.11110239]\n",
      " [-0.87227059]]\n"
     ]
    }
   ],
   "source": [
    "E = Y - output\n",
    "print (E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Compute slope at output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20761262]\n",
      " [0.20645991]\n",
      " [0.2078856 ]]\n"
     ]
    }
   ],
   "source": [
    "slope_output_layer= derivatives_sigmoid(output)\n",
    "print (slope_output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21174717 0.21787468 0.20645591]\n",
      " [0.20929257 0.20799233 0.20390232]\n",
      " [0.22293183 0.21743793 0.20742919]]\n"
     ]
    }
   ],
   "source": [
    "slope_hidden_layer = derivatives_sigmoid(hiddenlayer_activations)\n",
    "print (slope_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Compute delta at output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02585465]\n",
      " [ 0.02293819]\n",
      " [-0.18133249]]\n"
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "d_output = E * slope_output_layer*lr\n",
    "print (d_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Calculate Error at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00542948  0.02404483  0.00956622]\n",
      " [ 0.00481702  0.02133252  0.00848713]\n",
      " [-0.03807982 -0.16863922 -0.06709302]]\n"
     ]
    }
   ],
   "source": [
    "Error_at_hidden_layer = np.dot(d_output, wout.T)\n",
    "print (Error_at_hidden_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Compute delta at hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00114968  0.00523876  0.001975  ]\n",
      " [ 0.00100817  0.004437    0.00173055]\n",
      " [-0.0084892  -0.03666856 -0.01391705]]\n"
     ]
    }
   ],
   "source": [
    "d_hiddenlayer = Error_at_hidden_layer * slope_hidden_layer\n",
    "print (d_hiddenlayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Update weight at both output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.2087738 ]\n",
      " [0.92875579]\n",
      " [0.3687587 ]]\n"
     ]
    }
   ],
   "source": [
    "wout = wout + np.dot(hiddenlayer_activations, d_output) * learning_rate\n",
    "print (wout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51002158 0.77009676 0.87003706]\n",
      " [0.00991511 0.30963331 0.95986083]\n",
      " [0.51002158 0.32009676 0.54003706]\n",
      " [0.21992519 0.80967768 0.33987813]]\n"
     ]
    }
   ],
   "source": [
    "wh = wh+ np.dot(X.T,d_hiddenlayer) * learning_rate\n",
    "print (wh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Update biases at both output and hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.53993669 0.00973007 0.66989788]]\n"
     ]
    }
   ],
   "source": [
    "bh = bh + np.sum(d_hiddenlayer, axis=0) * learning_rate\n",
    "print (bh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7486746]]\n"
     ]
    }
   ],
   "source": [
    "bout = bout + np.sum(d_output, axis=0)*learning_rate\n",
    "print (bout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
